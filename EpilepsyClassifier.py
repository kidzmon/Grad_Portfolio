# -*- coding: utf-8 -*-
"""EpilepsyClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1paklEuwIdLJdCaymkSuonxycGFvt3lOl

# MNE library install
"""

!pip install mne
!pip install mne-features
!pip install yasa

"""# Import libary"""

import matplotlib.pyplot as plt
import numpy as np
import mne
import os
import mne_features
import yasa

from mne.time_frequency import psd_welch
from scipy import signal
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

"""## Data Load

(ref)
https://mne.tools/0.16/auto_tutorials/plot_introduction.html
"""

epilepsy_data_folder = '/content/drive/My Drive/Colab Notebooks/EEG/Dataset/EPILEPSY/'
noepilepsy_data_folder = '/content/drive/My Drive/Colab Notebooks/EEG/Dataset/NO EPILEPSY/'
epfnames = os.listdir(epilepsy_data_folder)[:-1]
noepfnames = os.listdir(noepilepsy_data_folder)[:-1]
channels = dict()
epraws = []
noepraws = []
for f in epfnames:
  epraw = mne.io.read_raw_edf(epilepsy_data_folder+f, preload=True)
  epraws.append(epraw)
  for ch in epraw.info['ch_names']:
    if ch in channels:
      channels[ch] += 1
    else:
      channels[ch] = 1
for f in noepfnames:
  noepraw = mne.io.read_raw_edf(noepilepsy_data_folder+f, preload=True)
  noepraws.append(noepraw)

print(len(epfnames))
print(channels)
print(epfnames)
print(len(noepfnames))

# picks : 24 channels that every raw have
picks = [ch for ch in channels if channels[ch] >= len(epfnames)]
print(picks)
print(len(picks))


print(epraws[0])
print(epraws[0].info)
print(epraws[0]['data'])
print(len(epraws[0]['data'][0][0]))

"""# Preprocessing

####Common spatial patterns(CSP) : channel selection
####Independent Component Analysis(ICA) : remove artifacts or select latent sources
####**Power spectral density(PSD)**
####**Bandpower : Delta, Theta, Alpha, Beta, Sigma, Gamma, TotalAbsPow**, FreqResponse, Relative
####Signal Space Projection(SSP) : remove ECG and EOG artifacts
####Maxwell Filters:(Signal Space Separation, SSS) : remove environmental noise
####Dipole Fit
####mne_features.feature_extraction.FeatureExtractor

####dataset :
channel - bandpower : channel * (8 columns - Delta, Theta, Alpha, Sigma, Beta, Gamma, TotalAbsPow, FreqResponse)
psd infomation
label - epilepsy / no epilepsy
"""

import pandas as pd
raw = epraws[0]
raw.pick_channels(picks)
bp = yasa.bandpower(raw)
bp = bp.drop(['Relative'], axis=1)
data = dict()
for row in bp.index:
  for col in bp.columns:
    data[row+' '+col] = bp[col][row]
psds, freqs = psd_welch(raw)
chidc = raw.ch_names
psds /= np.sum(psds, axis=-1, keepdims=True)
for chidx, chidx_name in enumerate(chidc):
  for fridx, freq in enumerate(freqs):
    data[chidx_name +' freq '+ str(round(freq,2))] = psds[chidx][fridx]
data['label'] = 'epilepsy'
print(data)
df_data = pd.DataFrame(data, index = [0])
print(df_data)

from sklearn.model_selection import train_test_split
import pandas as pd

datas = []
patient_no = 0
print('EPILEPSY')
for raw in epraws:
  print('-------------------------------------------------------')
  print(patient_no)
  raw.pick_channels(picks)
  print('psd plot')
  raw.plot_psd()
  print('raw plot')
  raw.plot()
  data = dict()

  bp = yasa.bandpower(raw)
  bp = bp.drop(['Relative'], axis=1)
  for row in bp.index:
    for col in bp.columns:
      data[row+' '+col] = bp[col][row]
  chidc = raw.ch_names
  psds, freqs = psd_welch(raw)
  psds /= np.sum(psds, axis=-1, keepdims=True)
  for chidx, chidx_name in enumerate(chidc):
    for fridx, freq in enumerate(freqs):
      data[chidx_name +' freq '+ str(round(freq,2))] = psds[chidx][fridx]
  data['label'] = 'epilepsy'
  print('psd')
  print(psds)
  print('freq')
  print(freqs)
  print('bandpower')
  print(bp)
  df_data = pd.DataFrame(data, index = [patient_no])
  patient_no += 1
  if len(datas) == 0:
    datas = df_data
  else:
    datas = pd.concat([datas, df_data])

print('NO EPILEPSY')
for raw in noepraws:
  print('-------------------------------------------------------')
  raw.pick_channels(picks)
  print('psd plot')
  raw.plot_psd()
  print('raw plot')
  raw.plot()
  data = dict()

  bp = yasa.bandpower(raw)
  bp = bp.drop(['Relative'], axis=1)
  for row in bp.index:
    for col in bp.columns:
      data[row+' '+col] = bp[col][row]
  chidc = raw.ch_names
  psds, freqs = psd_welch(raw)
  psds /= np.sum(psds, axis=-1, keepdims=True)
  for chidx, chidx_name in enumerate(chidc):
    for fridx, freq in enumerate(freqs):
      data[chidx_name +' freq '+ str(round(freq,2))] = psds[chidx][fridx]
  data['label'] = 'no epilepsy'
  
  print('psd')
  print(psds)
  print('freq')
  print(freqs)
  print('bandpower')
  print(bp)
  df_data = pd.DataFrame(data, index = [patient_no])
  patient_no += 1
  datas = pd.concat([datas, df_data])
print(datas)

"""PSD (flatten) + Bandpower(flatten) + Label
###Example
channel = 24
- Bandpower flatten = 8 * 24 = 192
- PSD flatten = 24 * 129 = 3,096
- label = 1
- data : 192 + 3,096 + 1 = 3,288 + 1 columns

# Prepare Train and Test Data and Label
"""

from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_validate

X = datas.drop(['label'], axis=1)
print(X)

imp = SimpleImputer(missing_values=np.nan, strategy = 'constant', fill_value = 0)
imp = imp.fit(X)

X = imp.transform(X)

y = datas['label']
class_le = LabelEncoder()
class_le.fit(['epilepsy', 'no epilepsy'])
print(class_le.classes_)
y = class_le.transform(y)

scoring = ['accuracy', 'recall', 'precision', 'f1']

max_estimator_dict = dict()
mean_dict = dict()
max_dict = dict()

print(X)
print(y)

"""# Model Learning

### Logistic Regression
"""

from sklearn.linear_model import LogisticRegression
logistic_reg_pipe = Pipeline([('scaler',StandardScaler()), ('clf', LogisticRegression(multi_class='auto', solver = 'liblinear', random_state = 42))])
logistic_reg_pipe.fit(X, y)
scores = cross_validate(logistic_reg_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['logistic regression'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['logistic regression'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['logistic regression'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Ridge Classifier"""

from sklearn.linear_model import RidgeClassifier
ridge_reg_pipe = Pipeline([('scaler',StandardScaler()), ('clf', RidgeClassifier(random_state = 42))])
ridge_reg_pipe.fit(X, y)
scores = cross_validate(ridge_reg_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['ridge regression'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['ridge regression'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['ridge regression'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Support Vector Classifier"""

from sklearn.svm import SVC
svm_pipe = Pipeline([('scaler',StandardScaler()), ('clf', SVC(random_state = 42))])
svm_pipe.fit(X, y)
scores = cross_validate(svm_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['SVC'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['SVC'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['SVC'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Linear Support Vector Classifier"""

from sklearn.svm import LinearSVC
linear_svm_pipe = Pipeline([('scaler',StandardScaler()), ('clf', LinearSVC(multi_class='crammer_singer', max_iter=10000, random_state = 42))])
linear_svm_pipe.fit(X, y)
scores = cross_validate(linear_svm_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['Linear SVC'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['Linear SVC'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['Linear SVC'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier
random_forest_pipe = Pipeline([('scaler',StandardScaler()), ('clf', RandomForestClassifier(random_state = 42))])
random_forest_pipe.fit(X, y)
scores = cross_validate(random_forest_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['random forest'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['random forest'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['random forest'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""Bernoulli Naive Bayes"""

from sklearn.naive_bayes import BernoulliNB
bernoulli_nb_pipe = Pipeline([('scaler',StandardScaler()), ('clf', BernoulliNB())])
bernoulli_nb_pipe.fit(X, y)
scores = cross_validate(bernoulli_nb_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['bernoulli NB'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['bernoulli NB'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['bernoulli NB'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Gaussian Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
gaussian_nb_pipe = Pipeline([('scaler',StandardScaler()), ('clf', GaussianNB())])
gaussian_nb_pipe.fit(X, y)
scores = cross_validate(gaussian_nb_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['gaussian NB'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['gaussian NB'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['gaussian NB'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
decision_tree_pipe = Pipeline([('scaler',StandardScaler()), ('clf', DecisionTreeClassifier(random_state = 42))])
decision_tree_pipe.fit(X, y)
scores = cross_validate(decision_tree_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['decision tree'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['decision tree'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['decision tree'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Extra Tree"""

from sklearn.tree import ExtraTreeClassifier
extra_tree_pipe = Pipeline([('scaler',StandardScaler()), ('clf', ExtraTreeClassifier(random_state = 42))])
extra_tree_pipe.fit(X, y)
scores = cross_validate(extra_tree_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['extra tree'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['extra tree'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['extra tree'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### K Neighbors Classifier"""

from sklearn.neighbors import KNeighborsClassifier
kneighbors_pipe = Pipeline([('scaler',StandardScaler()), ('clf', KNeighborsClassifier(n_neighbors=5))])
kneighbors_pipe.fit(X, y)
scores = cross_validate(kneighbors_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['k neighbors'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['k neighbors'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['k neighbors'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Nearest Centroid"""

from sklearn.neighbors import NearestCentroid
nearest_centroid_pipe = Pipeline([('scaler',StandardScaler()), ('clf', NearestCentroid())])
nearest_centroid_pipe.fit(X, y)
scores = cross_validate(nearest_centroid_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['nearest centroid'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['nearest centroid'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['nearest centroid'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""### Multi-Layer Perceptron Classifier"""

from sklearn.neural_network import MLPClassifier
mlp_pipe = Pipeline([('scaler',StandardScaler()), ('clf', MLPClassifier(random_state = 42))])
mlp_pipe.fit(X, y)
scores = cross_validate(mlp_pipe, X, y, scoring = scoring, cv = 3, return_estimator = True)

max_estimator_dict['mlp'] = scores['estimator'][scores['test_accuracy'].argmax()]
mean_dict['mlp'] = [scores['test_accuracy'].mean(), scores['test_recall'].mean(), scores['test_precision'].mean(), scores['test_f1'].mean()]
max_dict['mlp'] = [scores['test_accuracy'].max(), scores['test_recall'].max(), scores['test_precision'].max(), scores['test_f1'].max()]

"""## Mean Accuracy Rank"""

mean_accuracy = [(x, round(mean_dict[x][0], 5)) for x in mean_dict.keys()]
mean_accuracy.sort(key = lambda x:x[1], reverse=True)
plt.figure(figsize=(18,3))
plt.ylim(0.5,0.9)
plt.bar(*zip(*mean_accuracy))
for x, y in mean_accuracy:
  plt.text(x, y, str(y)+'\n', horizontalalignment='center')
plt.xlabel("model")
plt.ylabel("accuracy")
plt.title("Model Accuracy")
plt.show()

"""## Mean Recall Rank"""

mean_recall = [(x, round(mean_dict[x][1], 5)) for x in mean_dict.keys()]
mean_recall.sort(key = lambda x:x[1], reverse=True)
plt.figure(figsize=(18,3))
plt.ylim(0.0,0.7)
plt.bar(*zip(*mean_recall))
for x, y in mean_recall:
  plt.text(x, y, str(y)+'\n', horizontalalignment='center')
plt.xlabel("model")
plt.ylabel("recall")
plt.title("Model Recall")
plt.show()

"""## Mean Precision Rank"""

mean_precision = [(x, round(mean_dict[x][2], 5)) for x in mean_dict.keys()]
mean_precision.sort(key = lambda x:x[1], reverse=True)
plt.figure(figsize=(18,3))
plt.ylim(0.1,0.8)
plt.bar(*zip(*mean_precision))
for x, y in mean_precision:
  plt.text(x, y, str(y)+'\n', horizontalalignment='center')
plt.xlabel("model")
plt.ylabel("precision")
plt.title("Model Precision")
plt.show()

"""## Mean F1 Rank"""

mean_f1 = [(x, round(mean_dict[x][3], 5)) for x in mean_dict.keys()]
mean_f1.sort(key = lambda x:x[1], reverse=True)
plt.figure(figsize=(18,3))
plt.ylim(0.1,0.8)
plt.bar(*zip(*mean_f1))
for x, y in mean_f1:
  plt.text(x, y, str(y)+'\n', horizontalalignment='center')
plt.xlabel("model")
plt.ylabel("f1 score")
plt.title("Model F1")
plt.show()

"""## Max Accuracy Rank"""

max_accuracy = [(x, round(max_dict[x][0], 5)) for x in max_dict.keys()]
max_accuracy.sort(key = lambda x:x[1], reverse=True)
plt.figure(figsize=(18,3))
plt.ylim(0.6,0.9)
plt.bar(*zip(*max_accuracy))
for x, y in max_accuracy:
  plt.text(x, y, str(y)+'\n', horizontalalignment='center')
plt.xlabel("model")
plt.ylabel("accuracy")
plt.title("Model Max Accuracy")
plt.show()

"""## Max Recall Rank"""

max_recall = [(x, round(max_dict[x][1], 5)) for x in max_dict.keys()]
max_recall.sort(key = lambda x:x[1], reverse=True)
plt.figure(figsize=(18,3))
plt.ylim(0.1,0.9)
plt.bar(*zip(*max_recall))
for x, y in max_recall:
  plt.text(x, y, str(y)+'\n', horizontalalignment='center')
plt.xlabel("model")
plt.ylabel("recall")
plt.title("Model Max Recall")
plt.show()

"""## Max Precision Rank"""

max_precision = [(x, round(max_dict[x][2], 5)) for x in max_dict.keys()]
max_precision.sort(key = lambda x:x[1], reverse=True)
plt.figure(figsize=(18,3))
plt.ylim(0.2,0.9)
plt.bar(*zip(*max_precision))
for x, y in max_precision:
  plt.text(x, y, str(y)+'\n', horizontalalignment='center')
plt.xlabel("model")
plt.ylabel("precision")
plt.title("Model Max Precision")
plt.show()

"""## Max F1 Rank"""

max_f1 = [(x, round(max_dict[x][3], 5)) for x in max_dict.keys()]
max_f1.sort(key = lambda x:x[1], reverse=True)
plt.figure(figsize=(18,3))
plt.ylim(0.1,0.8)
plt.bar(*zip(*max_f1))
for x, y in max_f1:
  plt.text(x, y, str(y)+'\n', horizontalalignment='center')
plt.xlabel("model")
plt.ylabel("f1")
plt.title("Model Max F1")
plt.show()

"""## GridSearch Linear SVC and MLP"""

X = datas.drop(['label'], axis=1)
print(X)

imp = SimpleImputer(missing_values=np.nan, strategy = 'constant', fill_value = 0)
imp = imp.fit(X)

X = imp.transform(X)

y = datas['label']
class_le = LabelEncoder()
class_le.fit(['epilepsy', 'no epilepsy'])
print(class_le.classes_)
y = class_le.transform(y)

scoring = ['accuracy', 'recall', 'precision', 'f1']

max_estimator_dict = dict()
mean_dict = dict()
max_dict = dict()

print(X)
print(y)

from sklearn.model_selection import GridSearchCV
scaler_tuple = ('scaler', StandardScaler())
model_tuple = ('mlp', MLPClassifier(random_state=42))
pipe = Pipeline([scaler_tuple, model_tuple])
pipe.fit(X, y)
parms = {'mlp__hidden_layer_sizes' : [100, 200, 300, 400, 500], 'mlp__solver' : ['sgd', 'adam'], 'mlp__max_iter' : [200, 500, 1000, 5000, 10000]}
clf = GridSearchCV(pipe, param_grid=parms, cv = 3, scoring = 'accuracy', verbose = 3)
clf.fit(X, y)

print(clf.scorer_)
print(clf.cv_results_)
print(clf.score)
print(clf.estimator)
print(clf.best_params_)
print(clf.best_score_)

from sklearn.model_selection import GridSearchCV
scaler_tuple = ('scaler', StandardScaler())
svc_model_tuple = ('svc', LinearSVC(random_state=42))
svc_pipe = Pipeline([scaler_tuple, svc_model_tuple])
svc_pipe.fit(X, y)
svc_parms = {'svc__loss': ['hinge','squared_hinge'], 'svc__C' : [0.01, 0.1, 1, 10], 'svc__dual' : [True, False]}
svc_clf = GridSearchCV(svc_pipe, param_grid=svc_parms, cv = 3, scoring = 'accuracy', verbose = 3)
svc_clf.fit(X, y)

print(svc_clf.best_score_)
print(svc_clf.best_params_)